# ansible-managed in ooni-sysadmin.git

{% import 'common.j2' as c %}

proxy_cache_path /var/cache/nginx-api keys_zone=api:1M inactive=1h;

# moderate throttling applied globally
limit_req_zone $binary_remote_addr zone=limit_qps:60m rate=120r/m;
limit_req_log_level info;

server {
    listen 80;
    listen 443 ssl http2;

    keepalive_timeout 120 120; # http://kb.mozillazine.org/Network.http.keep-alive.timeout

    {{ c.ssl_letsencrypt(ssl_domain) }}

    server_name api.ooni.io {{ ssl_domain }};
    access_log  /var/log/nginx/{{ ssl_domain }}.access.log oolog;
    error_log   /var/log/nginx/{{ ssl_domain }}.error.log warn;

    proxy_read_timeout {{ oomsm_timeout_s }}s;


    location / {
        proxy_pass http://{{ oomsm_backend_ipv4 }}:{{ oomsm_backend_port }};
    }

    {{ c.location_letsencrypt() }}

    # Limit all requests to 10 per second
    limit_req zone=limit_qps burst=10 nodelay;

    location = /api/v1/measurements {
        proxy_pass http://{{ oomsm_backend_ipv4 }}:{{ oomsm_backend_port }};

        proxy_cache_min_uses 3; # this should avoid polluting the cache with random measurements search queries
        proxy_cache api;
        proxy_cache_valid 200 1h;
        proxy_cache_lock on;
        proxy_cache_lock_timeout 58s;
        proxy_cache_lock_age 58s;
        proxy_cache_use_stale error timeout invalid_header updating;
        proxy_cache_background_update on;

        # These queries are very heavy and can include offset limits
        limit_req zone=limit_qps burst=2 nodelay;
    }

    location /api/v1/ {
        proxy_pass http://{{ oomsm_backend_ipv4 }}:{{ oomsm_backend_port }};

        # These are all the public API endpoints, so we rate them limit them too
        limit_req zone=limit_qps burst=5 nodelay;
    }

{% for handle in ["/", "/stats", "/api/_/global_overview", "/api/_/global_overview_by_month", "/api/_/measurement_count_by_country", "/api/_/runs_by_month", "/api/_/countries_by_month", "/api/_/asn_by_month"] %}
    location = {{ handle }} {
        proxy_pass http://{{ oomsm_backend_ipv4 }}:{{ oomsm_backend_port }};

        proxy_cache api;
        proxy_cache_valid 200 1h;
        proxy_cache_lock on;
        proxy_cache_lock_timeout 58s;
        proxy_cache_lock_age 58s; # I don't quite understand the difference with proxy_cache_lock_timeout
        proxy_cache_use_stale error timeout invalid_header updating;
        proxy_cache_background_update on;
    }
{% endfor %}

# These caches are for the legacy OONI Explorer. We should drop them once the
# API endpoints are dropped.
{% for handle in ["/api/_/blockpages", "/api/_/blockpage_detected", "/api/_/blockpage_count"] %}
    location = {{ handle }} {
        proxy_pass http://{{ oomsm_backend_ipv4 }}:{{ oomsm_backend_port }};

        proxy_cache api;
        proxy_cache_valid 200 6h;
        proxy_cache_lock on;
        proxy_cache_lock_timeout 58s;
        proxy_cache_lock_age 58s;
        proxy_cache_use_stale error timeout invalid_header updating;
        proxy_cache_background_update on;
    }
{% endfor %}

    location /metrics {
        #satisfy all;
        #allow {{ lookup('dig', 'prometheus.infra.ooni.io/A') }}/32;
        #deny all;

        proxy_pass http://{{ oomsm_backend_ipv4 }}:{{ oomsm_prometheus_port }};
        proxy_http_version 1.1;
    }
}
