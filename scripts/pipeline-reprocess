#!/usr/bin/make -f

.SILENT: # to avoid useless echo before `ONESHELL` invocation
.ONESHELL: # to use here-docs
.SHELLFLAGS = -xec # xtrace, errexit, command
SHELL = /bin/bash
MAKEFLAGS = --jobs 5 --load-average 8 --keep-going # datacollector.infra.ooni.io specs

.PHONY: all clean reprocess

# all flag files are created in separate directory
PRJ = upcan
AF_TASK = canned_s3_sync
-include $(PRJ)/af-deps

ifndef TMUX
    $(error Run this makefile under TMUX)
endif

all: reprocess

$(PRJ)/.keep :
	mkdir -p $(PRJ)
	touch $@

$(PRJ)/af-deps : $(PRJ)/.keep
	set +o xtrace
	. <(sudo docker inspect af-psql | jq -r '.[].Config.Env[] | select(startswith("POSTGRES_"))' | sed 's/^POSTGRES_/PG/')
	set -o xtrace
	export PGUSER PGPASSWORD
	export PGHOSTADDR=`sudo docker inspect af-psql | jq -r '.[].NetworkSettings.Networks.af.IPAddress'`
	psql airflow --no-align --tuples-only '--set=prj=$(PRJ)' >$@.tmp <<EOF
	SELECT 'reprocess : ' || :'prj' || '/' || execution_date::date || '.tiflag'
	FROM task_instance
	WHERE dag_id = 'hist_canning' AND task_id = 'canning'
	EOF
	mv $@.tmp $@

$(PRJ)/metadb-deps : $(PRJ)/.keep
	set +o xtrace
	. <(sudo cat /srv/etc/af-worker/hkgmetadb.env)
	set -o xtrace
	export PGPASSWORD
	psql --host=hkgmetadb.infra.ooni.io --username shovel --dbname metadb --no-align --tuples-only '--set=prj=$(PRJ)' >$@.tmp <<EOF
	SELECT 'reprocess : ' || :'prj' || '/' || bucket_date || '.tiflag'
	FROM autoclaved
	GROUP BY bucket_date
	HAVING MIN(code_ver) < 4
	ORDER BY bucket_date
	EOF
	mv $@.tmp $@

$(PRJ)/%.tiflag: $(PRJ)/.keep
	set +o xtrace
	. <(sudo docker inspect af-psql | jq -r '.[].Config.Env[] | select(startswith("POSTGRES_"))' | sed 's/^POSTGRES_/PG/')
	set -o xtrace
	export PGUSER PGPASSWORD
	export PGHOSTADDR=`sudo docker inspect af-psql | jq -r '.[].NetworkSettings.Networks.af.IPAddress'`
	start=`psql --dbname airflow --no-align --tuples-only -c 'select CURRENT_TIMESTAMP'`
	# flock is here to avoid concurrent start
	flock $(PRJ)/.keep sudo docker exec -i af-websrv airflow run --force hist_canning $(AF_TASK) '$*T00:00:00'
	while [ `psql --dbname airflow --no-align --tuples-only "--set=start=$$start" '--set=ex=$*T00:00:00' <<EOF
	SELECT COUNT(*) FROM task_instance
	WHERE dag_id = 'hist_canning' AND task_id = '$(AF_TASK)' AND execution_date = :'ex' AND :'start' < end_date
	EOF` != 1 ]; do sleep 5; done
	date >$@
